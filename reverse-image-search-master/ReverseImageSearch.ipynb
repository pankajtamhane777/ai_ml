{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import distance\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os, logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image path for feature extraction\n",
    "images_path = \"set your image path\"\n",
    "images = os.listdir(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations = []\n",
    "\n",
    "for idx,image_path in enumerate(images):\n",
    "    if idx%20==0:\n",
    "        # print \"getting activations for %d/%d %s\" % (idx+1, len(images), image_path)\n",
    "        logging.info(\"getting activations for %d/%d %s\" % (idx+1, len(images), image_path))\n",
    "\n",
    "    img = image.load_img(images_path+image_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    feat = model.predict(x)\n",
    "    activations.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the feature file \n",
    "with h5py.File(\"/feature.hdf5\", \"w\") as hf:\n",
    "\tdt = h5py.special_dtype(vlen=unicode)\n",
    "\thf.create_dataset(\"images\", (len(images),), dtype=dt, data=images)\n",
    "\thf.create_dataset(\"imgfeatures\", (len(activations),4096), data=activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set your image path\n",
    "images_path_1 = \"image path for query images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the stored feature file\n",
    "with h5py.File(\"./validate/features/shopfeat.hdf5\", \"r\") as hf:\n",
    "\tprint (hf.keys())\n",
    "\timages = hf.get('images')\n",
    "\timages = list(images)\n",
    "\timgfeat = hf.get('imgfeatures')\n",
    "\timgfeat = list(imgfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reduce the number of features using Principle Component Analysis\n",
    "featacts = np.array(imgfeat)\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(featacts)\n",
    "acts = pca.transform(featacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#incase you want to save the pca file for further use\n",
    "# acts.shape\n",
    "# with h5py.File(\"features/pca_activations.hdf5\", \"w\") as hf:\n",
    "# \tdt = h5py.special_dtype(vlen=unicode)\n",
    "# \thf.create_dataset(\"pca_acts\", (len(acts),300), data=acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_concatenated_images(indexes, thumb_height):\n",
    "    thumbs = []\n",
    "    for idx in indexes:\n",
    "        img = Image.open(images_path+images[idx])\n",
    "        img = img.resize((img.width * thumb_height / img.height, thumb_height), Image.ANTIALIAS)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        thumbs.append(img)\n",
    "    concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n",
    "    return concat_image\n",
    "\n",
    "def get_image(path, thumb_height):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((img.width * thumb_height / img.height, thumb_height), Image.ANTIALIAS)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_images(query_image_idx, num_results=7):\n",
    "    thumb_height = 200\n",
    "    distances = [ distance.euclidean(acts[query_image_idx], act) for act in acts ]\n",
    "    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:num_results+1]\n",
    "    return idx_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_query():\n",
    "    query_image_idx = int(401*random.random())\n",
    "    idx_closest = get_closest_images(query_image_idx)\n",
    "    query_image = get_concatenated_images([query_image_idx], 300)\n",
    "    results_image = get_concatenated_images(idx_closest, 200)\n",
    "\n",
    "    matplotlib.pyplot.figure(figsize = (5,5))\n",
    "    imshow(query_image)\n",
    "    matplotlib.pyplot.title(\"query image (%d)\" % query_image_idx)\n",
    "    matplotlib.pyplot.figure(figsize = (12,12))\n",
    "    imshow(results_image)\n",
    "    matplotlib.pyplot.title(\"result images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# query_image = np.asarray(get_image(\"testImages/saree_girl.jpg\", 300))\n",
    "# print query_image.shape\n",
    "# thumb_height = 200\n",
    "# distances = [ distance.euclidean(query_image, act) for act in acts ]\n",
    "# idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:num_results+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = image.load_img(\"/home/pankaj/anaconda2/image_experiment/validate/exp1/dog.1028.jpg\", target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "feat = model.predict(x)\n",
    "feat = feat.reshape(4096,)\n",
    "lst = []\n",
    "lst.append(feat)\n",
    "lst = pca.transform(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = [ distance.euclidean(lst[0], act) for act in acts ]\n",
    "idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:5+1]\n",
    "results_image = get_concatenated_images(idx_closest, 200)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize = (5,5))\n",
    "imshow(img)\n",
    "matplotlib.pyplot.title(\"query image original\")\n",
    "matplotlib.pyplot.figure(figsize = (12,12))\n",
    "imshow(results_image)\n",
    "matplotlib.pyplot.title(\"result images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(acts)\n",
    "tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, verbose=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize t-sne points to {0,1}\n",
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width = 3000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "full_image = Image.new('RGB', (width, height))\n",
    "for img, x, y in zip(images, tx, ty):\n",
    "    tile = Image.open(images_path)\n",
    "    rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "    tile = tile.resize((tile.width/rs, tile.height/rs), Image.ANTIALIAS)\n",
    "    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)))\n",
    "\n",
    "matplotlib.pyplot.figure(figsize = (12,12))\n",
    "imshow(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
